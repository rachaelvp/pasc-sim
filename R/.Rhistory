)
learner_list <- list(A = sl_A, Y = sl_Y)
# HAL spec
### This name needs to be used
lrnr_uhal <- Lrnr_uhal9001$new()
lrnr_uhalcv <- Lrnr_uhal9001cv$new()
# Set up Sim
## Specs for SL and HAL and TMLE
# B is number of simulations
tmle.res <- NULL
simp.res <- NULL
df <- generate_data_simple(N=500)
df[1:10,]
# Load Libraries
library(hal9001)
library(glmnet)
library(stringi)
library(dplyr)
##simulate training data:
set.seed(1231)
library(ggplot2)
sim.true <- function() {
X <- seq(-4,4,length=500)
#stepwise function between X and Y
EY <- -1*(X > -3) + 3*(X > -2) + -2*(X > 0) + 4*(X>2) + -1*(X >3)
return(data.frame(X,EY)) }
dat <- sim.true()
plot(dat[,"X"],dat[,"EY"],xlab="x",ylab="E(Y|X)",type="s")
sim.dat <- function(n,sigma) {
X <- runif(n,-4,4)
#stepwise function between X and Y
Y <- -1*(X > -3) + 3*(X > -2) + -2*(X > 0) + 4*(X>2) + -1*(X >3)+
rnorm(n,0,sigma)
return(data.frame(X,Y)) }
dat <- sim.dat(100,0.50)
plot(dat$X,dat$Y,xlab="X",ylab="Y")
X <- as.matrix(dat$X)
Y <- as.vector(dat$Y)
hal.fit1 <- fit_hal(X,Y,family="gaussian",
X_unpenalized = NULL,
max_degree = ifelse(ncol(X) >= 20, 2, 3),
smoothness_orders = 0,
reduce_basis = 1 / sqrt(length(Y)),
fit_control = list(
cv_select = TRUE,
n_folds = 10,
foldid = NULL,
use_min = TRUE,
lambda.min.ratio = 1e-4,
prediction_bounds = "default"
),
basis_list = NULL,
return_lasso = TRUE,
return_x_basis = TRUE,
yolo = FALSE)
oo <- order(dat$X)
plotx <- dat$X[oo]
pred.fit1 <- predict(hal.fit1,new_data=plotx)
plot(dat$X,dat$Y)
lines(plotx,pred.fit1)
init_coef <-hal.fit1$coefs[-1]
nonzero_col <- which(init_coef != 0)
basis_mat <- as.matrix(hal.fit1$x_basis)
basis_mat <- as.matrix(basis_mat[, nonzero_col])
##  Get the cut-offs
cutoffs <- unlist(lapply(hal.fit1$basis_list, function (x) x['cutoffs']))
cutoffs <- cutoffs[nonzero_col]
coeff.not0 <- init_coef[nonzero_col]
intercpt <- hal.fit1$coefs[1]
##
form <- paste(round(coeff.not0,2),"*I(X >",round(cutoffs,2),")")
form <- stri_paste(form, collapse='+')
form <- paste(round(intercpt,2),form,sep="+")
form
generate_data_simple <- function(N,Wranges=c(-1,1,-1,1),betaA=c(0,0.1,-0.4),
betaY0=c(0,1,2,-1),betaC=c(1,7/5,5,3),sdy=1){
# A simple data generating process
W1 <- runif(N,Wranges[1],Wranges[2])
W2 <- runif(N,Wranges[3],Wranges[4])
pi0 <- plogis(betaA[1]+betaA[2]*W1*W2+betaA[3]*W1)
A <- rbinom(N,1,prob=pi0)
muY0 <- betaY0[1]+betaY0[2]*W1*W2 + betaY0[3]*W2^2 +betaY0[4]*W1
CATE <- betaC[1]*W1^2*(W1+betaC[2]) + (betaC[3]*W2/betaC[4])^2
muY = muY0+A*CATE
Y <- rnorm(N,sd=sdy,mean= muY)
return(tibble(W1=W1,W2=W2,A=A,Y=Y))
}
N=500
dat <- generate_data_simple(N)
True_value <- function(N=100000,Wranges=c(-1,1,-1,1), betaY0=c(0,1,2,-1),
betaC=c(1,7/5,5,3))
{
# A simple data generating process
W1 <- runif(N,Wranges[1],Wranges[2])
W2 <- runif(N,Wranges[3],Wranges[4])
muY0 <- betaY0[1]+betaY0[2]*W1*W2 + betaY0[3]*W2^2 +betaY0[4]*W1
CATE <- betaC[1]*W1^2*(W1+betaC[2]) + (betaC[3]*W2/betaC[4])^2
Y1 = muY0+CATE
muY1 = mean(Y1)
return(muY1)
}
True_value()
X <- as.matrix(dat[,-c(4)])
Y <- as.vector(dat$Y)
hal.fit2 <- fit_hal(X,Y,family="gaussian",
X_unpenalized = NULL,
max_degree = ifelse(ncol(X) >= 20, 2, 3),
smoothness_orders = 0,
reduce_basis = 1 / sqrt(length(Y)),
fit_control = list(
cv_select = TRUE,
n_folds = 10,
foldid = NULL,
use_min = TRUE,
lambda.min.ratio = 1e-4,
prediction_bounds = "default"
),
basis_list = NULL,
return_lasso = TRUE,
return_x_basis = TRUE,
yolo = FALSE)
pred.fit2 <- predict(hal.fit2,new_data=X)
plot(pred.fit2,Y, xlab="Predicted",ylab="Observed")
abline(0,1)
cor(pred.fit2,dat$Y)^2
dat.new <- generate_data_simple(N=500)
Xn <- as.matrix(dat.new[,-c(4)])
Yn <- as.vector(dat.new$Y)
pred.fitn <- predict(hal.fit2,new_data=Xn)
cor(pred.fitn,Yn)^2
init_coef <-hal.fit2$coefs
nonzero_col <- which(init_coef != 0)
length(init_coef[nonzero_col])
hal.fit2b <- fit_hal(X,Y,family="gaussian",
X_unpenalized = NULL,
max_degree = ifelse(ncol(X) >= 20, 2, 3),
smoothness_orders = 1,
reduce_basis = 1 / sqrt(length(Y)),
fit_control = list(
cv_select = TRUE,
n_folds = 10,
foldid = NULL,
use_min = TRUE,
lambda.min.ratio = 1e-4,
prediction_bounds = "default"
),
basis_list = NULL,
return_lasso = TRUE,
return_x_basis = TRUE,
yolo = FALSE)
length(hal.fit2$coefs)
init_coef <-hal.fit2b$coefs
nonzero_col <- which(init_coef != 0)
length(init_coef[nonzero_col])
Xn[,3] <- 1
pred.fitEY1 <- predict(hal.fit2b,new_data=Xn)
phihat <-mean(pred.fitEY1)
X[1:10,]
Xn[1:10,]
Xn <- as.matrix(dat.new[,-c(4)])
Xn[1:3,]
X[1:3,]
N=500
dat <- generate_data_simple(N)
dat[1:10,]
dat[1:15,]
dat[1:5,]
X <- as.matrix(dat[,-c(4)])
Y <- as.vector(dat$Y)
hal.fit2b <- fit_hal(X,Y,family="gaussian",
X_unpenalized = NULL,
max_degree = ifelse(ncol(X) >= 20, 2, 3),
smoothness_orders = 1,
reduce_basis = 1 / sqrt(length(Y)),
fit_control = list(
cv_select = TRUE,
n_folds = 10,
foldid = NULL,
use_min = TRUE,
lambda.min.ratio = 1e-4,
prediction_bounds = "default"
),
basis_list = NULL,
return_lasso = TRUE,
return_x_basis = TRUE,
yolo = FALSE)
Xn <- X
Xn[,3] <- 1
pred.fitEY1 <- predict(hal.fit2b,new_data=Xn)
phihat <-mean(pred.fitEY1)
phihat
dim(IC_beta)
coef <- hal.fit2b$coefs
# Need to add intercept to match dimension of coef
basis_mat <- cbind(1, as.matrix(hal.fit2b$x_basis))
nonzero_idx <- which(coef != 0)
coef_nonzero <- coef[nonzero_idx]
basis_mat_nonzero <- as.matrix(basis_mat[, nonzero_idx])
# Get predicted Y (from above)
Y_hat <- predict(hal.fit2b,new_data=X)
# IC_beta is a pxn matrix, where each row is the IC for a particular beta.
IC_beta <- cal_IC_for_beta(X = basis_mat_nonzero,
Y = Y,
Y_hat =Y_hat,
beta_n = coef_nonzero)
cal_IC_for_beta <- function(X, Y, Y_hat, beta_n){
n <- dim(X)[1]
p <- length(beta_n)
if (!is.matrix(X)) X <- as.matrix(X)
# 1. calculate score: X'(Y - phi(X))
res <- Y-Y_hat
score <- sweep(t(X), 2, res, `*`)
# 2. calculate the derivative of phi:
d_phi = - X
# 3. -E_{P_n}(X d_phi)^(-1)
tmat <- t(X) %*% d_phi / n
if(! is.matrix(try(solve(tmat), silent = TRUE))){
return(NA)
}
tmat <- -solve(tmat)
# 4. calculate influence curves
IC <- tmat %*% score
return(IC)
}
IC_beta <- cal_IC_for_beta(X = basis_mat_nonzero,
Y = Y,
Y_hat =Y_hat,
beta_n = coef_nonzero)
dim(IC_beta)
Xn[1:3,]
X[1:3,]
X_new <- make_design_matrix(Xn, hal.fit2b$basis_list, p_reserve = 0.75)
X_new <- cbind(1, X_new)
X_new <- as.matrix(X_new[, nonzero_idx])
dim(X_new)
dim(basis_mat)
dim(basis_mat_nonzero
)
cal_IC_for_EY <- function(X_new, IC_beta){
if (!is.matrix(X_new)) X_new <- as.matrix(X_new)
d_phi_new = X_new
IC = colMeans(d_phi_new %*% IC_beta)
return(IC)
}
ICEY1 <- cal_IC_for_EY(X_new,IC_beta)
length(ICEY1)
n <- length(ICEY1)
SE <- sqrt(mean(ICEY1^2)/n)
phihat+1.96*SE
phihat-1.96*SE
load("/Users/hubbard/UC Berkeley Biostat Dropbox/Alan Hubbard/hubbardlap/grantproposals/ki Gates/Synthetic data supp/GitSynth/pasc-sim/R/April19.rdata")
